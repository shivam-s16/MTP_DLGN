{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2342789",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-19T11:29:07.585945Z",
     "iopub.status.busy": "2025-11-19T11:29:07.585564Z",
     "iopub.status.idle": "2025-11-19T13:56:48.856019Z",
     "shell.execute_reply": "2025-11-19T13:56:48.854473Z"
    },
    "papermill": {
     "duration": 8861.277729,
     "end_time": "2025-11-19T13:56:48.858404",
     "exception": false,
     "start_time": "2025-11-19T11:29:07.580675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 30\n",
      "  Total Samples: 40000\n",
      "  Number of Classes: 3\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 13333\n",
      "  Class 1: 13333\n",
      "  Class 2: 13333\n",
      "\n",
      "Data split:\n",
      "  Training: 20000\n",
      "  Validation: 10000\n",
      "  Test: 9999\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [01:48<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.031172\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.65247\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.77888\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.53585\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.90339          0.09661\n",
      "Random Forest        0.65247          0.34753\n",
      "SVM                  0.77888          0.22112\n",
      "CART                 0.53585          0.46415\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         \n",
      "--------------------------------------------------------\n",
      "DLGN                0.92757    0.90186    0.88102    \n",
      "Random Forest       0.75696    0.60777    0.59256    \n",
      "SVM                 0.86770    0.73525    0.73339    \n",
      "CART                0.58456    0.55274    0.47151    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 40\n",
      "  Total Samples: 40000\n",
      "  Number of Classes: 3\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 13333\n",
      "  Class 1: 13333\n",
      "  Class 2: 13333\n",
      "\n",
      "Data split:\n",
      "  Training: 20000\n",
      "  Validation: 10000\n",
      "  Test: 9999\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [01:50<00:00, 13.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.076553\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.62476\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.75058\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.48575\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.88719          0.11281\n",
      "Random Forest        0.62476          0.37524\n",
      "SVM                  0.75058          0.24942\n",
      "CART                 0.48575          0.51425\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         \n",
      "--------------------------------------------------------\n",
      "DLGN                0.91077    0.85279    0.89815    \n",
      "Random Forest       0.71680    0.58973    0.56684    \n",
      "SVM                 0.83557    0.70827    0.70718    \n",
      "CART                0.53924    0.44730    0.47045    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 50\n",
      "  Total Samples: 40000\n",
      "  Number of Classes: 3\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 13333\n",
      "  Class 1: 13333\n",
      "  Class 2: 13333\n",
      "\n",
      "Data split:\n",
      "  Training: 20000\n",
      "  Validation: 10000\n",
      "  Test: 9999\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [02:07<00:00, 11.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.016354\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.65287\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.74747\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.47825\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.86779          0.13221\n",
      "Random Forest        0.65287          0.34713\n",
      "SVM                  0.74747          0.25253\n",
      "CART                 0.47825          0.52175\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         \n",
      "--------------------------------------------------------\n",
      "DLGN                0.88577    0.82680    0.89095    \n",
      "Random Forest       0.67029    0.55938    0.72901    \n",
      "SVM                 0.76216    0.69010    0.79026    \n",
      "CART                0.47869    0.42447    0.53152    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 30\n",
      "  Total Samples: 40000\n",
      "  Number of Classes: 4\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 10000\n",
      "  Class 1: 10000\n",
      "  Class 2: 10000\n",
      "  Class 3: 10000\n",
      "\n",
      "Data split:\n",
      "  Training: 20000\n",
      "  Validation: 10000\n",
      "  Test: 10000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [01:45<00:00, 14.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.083915\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.57540\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.73250\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.41790\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.89010          0.10990\n",
      "Random Forest        0.57540          0.42460\n",
      "SVM                  0.73250          0.26750\n",
      "CART                 0.41790          0.58210\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         Class 3         \n",
      "--------------------------------------------------------------------\n",
      "DLGN                0.85294    0.90205    0.88831    0.91723    \n",
      "Random Forest       0.47099    0.60177    0.61935    0.61043    \n",
      "SVM                 0.66852    0.71377    0.76855    0.77955    \n",
      "CART                0.37878    0.43798    0.39798    0.45682    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 40\n",
      "  Total Samples: 40000\n",
      "  Number of Classes: 4\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 10000\n",
      "  Class 1: 10000\n",
      "  Class 2: 10000\n",
      "  Class 3: 10000\n",
      "\n",
      "Data split:\n",
      "  Training: 20000\n",
      "  Validation: 10000\n",
      "  Test: 10000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [01:50<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.064057\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.49220\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.66420\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.36840\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.88940          0.11060\n",
      "Random Forest        0.49220          0.50780\n",
      "SVM                  0.66420          0.33580\n",
      "CART                 0.36840          0.63160\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         Class 3         \n",
      "--------------------------------------------------------------------\n",
      "DLGN                0.86268    0.88844    0.88607    0.92108    \n",
      "Random Forest       0.30550    0.58598    0.54426    0.53582    \n",
      "SVM                 0.55758    0.71728    0.66495    0.71914    \n",
      "CART                0.34824    0.38019    0.34458    0.40146    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 50\n",
      "  Total Samples: 40000\n",
      "  Number of Classes: 4\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 10000\n",
      "  Class 1: 10000\n",
      "  Class 2: 10000\n",
      "  Class 3: 10000\n",
      "\n",
      "Data split:\n",
      "  Training: 20000\n",
      "  Validation: 10000\n",
      "  Test: 10000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [02:02<00:00, 12.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.063614\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.55250\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.68530\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.40760\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.87480          0.12520\n",
      "Random Forest        0.55250          0.44750\n",
      "SVM                  0.68530          0.31470\n",
      "CART                 0.40760          0.59240\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         Class 3         \n",
      "--------------------------------------------------------------------\n",
      "DLGN                0.84562    0.87749    0.84452    0.92938    \n",
      "Random Forest       0.43980    0.50239    0.45761    0.80101    \n",
      "SVM                 0.60975    0.66879    0.60707    0.84940    \n",
      "CART                0.34767    0.39665    0.33588    0.54506    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 30\n",
      "  Total Samples: 40000\n",
      "  Number of Classes: 5\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 8000\n",
      "  Class 1: 8000\n",
      "  Class 2: 8000\n",
      "  Class 3: 8000\n",
      "  Class 4: 8000\n",
      "\n",
      "Data split:\n",
      "  Training: 20000\n",
      "  Validation: 10000\n",
      "  Test: 10000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [01:58<00:00, 12.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.058906\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.62280\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.77460\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.41680\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.91100          0.08900\n",
      "Random Forest        0.62280          0.37720\n",
      "SVM                  0.77460          0.22540\n",
      "CART                 0.41680          0.58320\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         Class 3         Class 4         \n",
      "--------------------------------------------------------------------------------\n",
      "DLGN                0.88695    0.93702    0.92038    0.89824    0.91289    \n",
      "Random Forest       0.59861    0.62878    0.72156    0.51486    0.64813    \n",
      "SVM                 0.78088    0.78546    0.82987    0.69572    0.78002    \n",
      "CART                0.36853    0.40911    0.47329    0.38035    0.45128    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 40\n",
      "  Total Samples: 40000\n",
      "  Number of Classes: 5\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 8000\n",
      "  Class 1: 8000\n",
      "  Class 2: 8000\n",
      "  Class 3: 8000\n",
      "  Class 4: 8000\n",
      "\n",
      "Data split:\n",
      "  Training: 20000\n",
      "  Validation: 10000\n",
      "  Test: 10000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [02:08<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.068977\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.53370\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.70570\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.35060\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.89000          0.11000\n",
      "Random Forest        0.53370          0.46630\n",
      "SVM                  0.70570          0.29430\n",
      "CART                 0.35060          0.64940\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         Class 3         Class 4         \n",
      "--------------------------------------------------------------------------------\n",
      "DLGN                0.88311    0.93219    0.89552    0.86663    0.87275    \n",
      "Random Forest       0.46855    0.72976    0.51848    0.56897    0.38673    \n",
      "SVM                 0.69143    0.83249    0.69443    0.71755    0.59481    \n",
      "CART                0.34720    0.42409    0.36175    0.33824    0.28244    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 50\n",
      "  Total Samples: 40000\n",
      "  Number of Classes: 5\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 8000\n",
      "  Class 1: 8000\n",
      "  Class 2: 8000\n",
      "  Class 3: 8000\n",
      "  Class 4: 8000\n",
      "\n",
      "Data split:\n",
      "  Training: 20000\n",
      "  Validation: 10000\n",
      "  Test: 10000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [01:54<00:00, 13.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.011959\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.50440\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.67090\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.33740\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.89860          0.10140\n",
      "Random Forest        0.50440          0.49560\n",
      "SVM                  0.67090          0.32910\n",
      "CART                 0.33740          0.66260\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         Class 3         Class 4         \n",
      "--------------------------------------------------------------------------------\n",
      "DLGN                0.88322    0.93027    0.89117    0.92131    0.86855    \n",
      "Random Forest       0.47272    0.52350    0.41240    0.73429    0.38900    \n",
      "SVM                 0.67772    0.68418    0.60810    0.80531    0.58617    \n",
      "CART                0.31362    0.35220    0.26940    0.48033    0.27751    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 30\n",
      "  Total Samples: 60000\n",
      "  Number of Classes: 3\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 20000\n",
      "  Class 1: 20000\n",
      "  Class 2: 20000\n",
      "\n",
      "Data split:\n",
      "  Training: 30000\n",
      "  Validation: 15000\n",
      "  Test: 15000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [02:15<00:00, 11.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.064905\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.66253\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.78893\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.53513\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.92567          0.07433\n",
      "Random Forest        0.66253          0.33747\n",
      "SVM                  0.78893          0.21107\n",
      "CART                 0.53513          0.46487\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         \n",
      "--------------------------------------------------------\n",
      "DLGN                0.95075    0.92475    0.90095    \n",
      "Random Forest       0.77699    0.62699    0.58103    \n",
      "SVM                 0.87333    0.75287    0.73868    \n",
      "CART                0.61288    0.51382    0.47695    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 40\n",
      "  Total Samples: 60000\n",
      "  Number of Classes: 3\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 20000\n",
      "  Class 1: 20000\n",
      "  Class 2: 20000\n",
      "\n",
      "Data split:\n",
      "  Training: 30000\n",
      "  Validation: 15000\n",
      "  Test: 15000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [02:16<00:00, 11.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.077499\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.62293\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.76507\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.48040\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.91047          0.08953\n",
      "Random Forest        0.62293          0.37707\n",
      "SVM                  0.76507          0.23493\n",
      "CART                 0.48040          0.51960\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         \n",
      "--------------------------------------------------------\n",
      "DLGN                0.94022    0.90472    0.88640    \n",
      "Random Forest       0.72195    0.59426    0.55215    \n",
      "SVM                 0.84985    0.71478    0.72947    \n",
      "CART                0.53406    0.45582    0.45082    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 50\n",
      "  Total Samples: 60000\n",
      "  Number of Classes: 3\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 20000\n",
      "  Class 1: 20000\n",
      "  Class 2: 20000\n",
      "\n",
      "Data split:\n",
      "  Training: 30000\n",
      "  Validation: 15000\n",
      "  Test: 15000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [02:38<00:00,  9.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.055547\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.65113\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.75913\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.48760\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.90807          0.09193\n",
      "Random Forest        0.65113          0.34887\n",
      "SVM                  0.75913          0.24087\n",
      "CART                 0.48760          0.51240\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         \n",
      "--------------------------------------------------------\n",
      "DLGN                0.92571    0.89172    0.90630    \n",
      "Random Forest       0.64256    0.58854    0.72191    \n",
      "SVM                 0.77025    0.72192    0.78471    \n",
      "CART                0.44631    0.49808    0.51926    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 30\n",
      "  Total Samples: 60000\n",
      "  Number of Classes: 4\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 15000\n",
      "  Class 1: 15000\n",
      "  Class 2: 15000\n",
      "  Class 3: 15000\n",
      "\n",
      "Data split:\n",
      "  Training: 30000\n",
      "  Validation: 15000\n",
      "  Test: 15000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [02:19<00:00, 10.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.090439\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.56613\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.74180\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.42493\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.91520          0.08480\n",
      "Random Forest        0.56613          0.43387\n",
      "SVM                  0.74180          0.25820\n",
      "CART                 0.42493          0.57507\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         Class 3         \n",
      "--------------------------------------------------------------------\n",
      "DLGN                0.89411    0.91084    0.91830    0.93851    \n",
      "Random Forest       0.45533    0.56917    0.63220    0.61082    \n",
      "SVM                 0.69522    0.72199    0.77177    0.78027    \n",
      "CART                0.37047    0.43161    0.46665    0.43209    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 40\n",
      "  Total Samples: 60000\n",
      "  Number of Classes: 4\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 15000\n",
      "  Class 1: 15000\n",
      "  Class 2: 15000\n",
      "  Class 3: 15000\n",
      "\n",
      "Data split:\n",
      "  Training: 30000\n",
      "  Validation: 15000\n",
      "  Test: 15000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [02:13<00:00, 11.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.076365\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.49107\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.67307\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.37880\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.91827          0.08173\n",
      "Random Forest        0.49107          0.50893\n",
      "SVM                  0.67307          0.32693\n",
      "CART                 0.37880          0.62120\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         Class 3         \n",
      "--------------------------------------------------------------------\n",
      "DLGN                0.90212    0.92645    0.91117    0.93298    \n",
      "Random Forest       0.28077    0.59373    0.56016    0.52823    \n",
      "SVM                 0.56637    0.72464    0.66864    0.73113    \n",
      "CART                0.31778    0.40972    0.40323    0.38417    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 50\n",
      "  Total Samples: 60000\n",
      "  Number of Classes: 4\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 15000\n",
      "  Class 1: 15000\n",
      "  Class 2: 15000\n",
      "  Class 3: 15000\n",
      "\n",
      "Data split:\n",
      "  Training: 30000\n",
      "  Validation: 15000\n",
      "  Test: 15000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [02:41<00:00,  9.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.098536\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.56073\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.70373\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.41233\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.89933          0.10067\n",
      "Random Forest        0.56073          0.43927\n",
      "SVM                  0.70373          0.29627\n",
      "CART                 0.41233          0.58767\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         Class 3         \n",
      "--------------------------------------------------------------------\n",
      "DLGN                0.87021    0.90315    0.87386    0.95003    \n",
      "Random Forest       0.40246    0.53337    0.50242    0.80434    \n",
      "SVM                 0.62113    0.69642    0.64658    0.85034    \n",
      "CART                0.37126    0.37737    0.34481    0.55420    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 30\n",
      "  Total Samples: 60000\n",
      "  Number of Classes: 5\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 12000\n",
      "  Class 1: 12000\n",
      "  Class 2: 12000\n",
      "  Class 3: 12000\n",
      "  Class 4: 12000\n",
      "\n",
      "Data split:\n",
      "  Training: 30000\n",
      "  Validation: 15000\n",
      "  Test: 15000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [02:34<00:00,  9.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.051928\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.61960\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.78753\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.42427\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.94093          0.05907\n",
      "Random Forest        0.61960          0.38040\n",
      "SVM                  0.78753          0.21247\n",
      "CART                 0.42427          0.57573\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         Class 3         Class 4         \n",
      "--------------------------------------------------------------------------------\n",
      "DLGN                0.93916    0.95417    0.95254    0.92443    0.93386    \n",
      "Random Forest       0.62709    0.59083    0.72187    0.50202    0.65530    \n",
      "SVM                 0.80536    0.77646    0.84135    0.71424    0.79918    \n",
      "CART                0.38862    0.43225    0.50083    0.33941    0.46028    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 40\n",
      "  Total Samples: 60000\n",
      "  Number of Classes: 5\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 12000\n",
      "  Class 1: 12000\n",
      "  Class 2: 12000\n",
      "  Class 3: 12000\n",
      "  Class 4: 12000\n",
      "\n",
      "Data split:\n",
      "  Training: 30000\n",
      "  Validation: 15000\n",
      "  Test: 15000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [02:46<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.060507\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.51793\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.71520\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.35040\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.92680          0.07320\n",
      "Random Forest        0.51793          0.48207\n",
      "SVM                  0.71520          0.28480\n",
      "CART                 0.35040          0.64960\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         Class 3         Class 4         \n",
      "--------------------------------------------------------------------------------\n",
      "DLGN                0.93125    0.95403    0.92059    0.91060    0.91730    \n",
      "Random Forest       0.43872    0.71329    0.56342    0.53373    0.34329    \n",
      "SVM                 0.67486    0.83962    0.73015    0.72017    0.61241    \n",
      "CART                0.34175    0.44213    0.37917    0.34297    0.24778    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 50\n",
      "  Total Samples: 60000\n",
      "  Number of Classes: 5\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 12000\n",
      "  Class 1: 12000\n",
      "  Class 2: 12000\n",
      "  Class 3: 12000\n",
      "  Class 4: 12000\n",
      "\n",
      "Data split:\n",
      "  Training: 30000\n",
      "  Validation: 15000\n",
      "  Test: 15000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [02:29<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.060603\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.50580\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.67767\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.33673\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.92280          0.07720\n",
      "Random Forest        0.50580          0.49420\n",
      "SVM                  0.67767          0.32233\n",
      "CART                 0.33673          0.66327\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         Class 3         Class 4         \n",
      "--------------------------------------------------------------------------------\n",
      "DLGN                0.90489    0.94143    0.91430    0.94287    0.91116    \n",
      "Random Forest       0.47457    0.49669    0.44381    0.69723    0.42272    \n",
      "SVM                 0.67900    0.69722    0.60954    0.79439    0.61162    \n",
      "CART                0.30086    0.34414    0.29910    0.45262    0.29062    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 30\n",
      "  Total Samples: 100000\n",
      "  Number of Classes: 3\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 33333\n",
      "  Class 1: 33333\n",
      "  Class 2: 33333\n",
      "\n",
      "Data split:\n",
      "  Training: 50000\n",
      "  Validation: 25000\n",
      "  Test: 24999\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [03:21<00:00,  7.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.066511\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.65619\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.79735\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.54538\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.94044          0.05956\n",
      "Random Forest        0.65619          0.34381\n",
      "SVM                  0.79735          0.20265\n",
      "CART                 0.54538          0.45462\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         \n",
      "--------------------------------------------------------\n",
      "DLGN                0.95877    0.93233    0.93042    \n",
      "Random Forest       0.76158    0.64307    0.56522    \n",
      "SVM                 0.88103    0.76452    0.74746    \n",
      "CART                0.64708    0.51395    0.47631    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 40\n",
      "  Total Samples: 100000\n",
      "  Number of Classes: 3\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 33333\n",
      "  Class 1: 33333\n",
      "  Class 2: 33333\n",
      "\n",
      "Data split:\n",
      "  Training: 50000\n",
      "  Validation: 25000\n",
      "  Test: 24999\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [02:58<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.081051\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.62931\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.77991\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.50290\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.93688          0.06312\n",
      "Random Forest        0.62931          0.37069\n",
      "SVM                  0.77991          0.22009\n",
      "CART                 0.50290          0.49710\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         \n",
      "--------------------------------------------------------\n",
      "DLGN                0.96048    0.91310    0.93717    \n",
      "Random Forest       0.71329    0.58636    0.58801    \n",
      "SVM                 0.85856    0.72810    0.75303    \n",
      "CART                0.56743    0.48719    0.45363    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 50\n",
      "  Total Samples: 100000\n",
      "  Number of Classes: 3\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 33333\n",
      "  Class 1: 33333\n",
      "  Class 2: 33333\n",
      "\n",
      "Data split:\n",
      "  Training: 50000\n",
      "  Validation: 25000\n",
      "  Test: 24999\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [03:33<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.086563\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.63735\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.77131\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.49394\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.93708          0.06292\n",
      "Random Forest        0.63735          0.36265\n",
      "SVM                  0.77131          0.22869\n",
      "CART                 0.49394          0.50606\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         \n",
      "--------------------------------------------------------\n",
      "DLGN                0.94346    0.92675    0.94109    \n",
      "Random Forest       0.67371    0.54594    0.69289    \n",
      "SVM                 0.79113    0.72960    0.79346    \n",
      "CART                0.48840    0.43637    0.55711    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 30\n",
      "  Total Samples: 100000\n",
      "  Number of Classes: 4\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 25000\n",
      "  Class 1: 25000\n",
      "  Class 2: 25000\n",
      "  Class 3: 25000\n",
      "\n",
      "Data split:\n",
      "  Training: 50000\n",
      "  Validation: 25000\n",
      "  Test: 25000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [03:20<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.117182\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.56728\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.76156\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.44376\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.93108          0.06892\n",
      "Random Forest        0.56728          0.43272\n",
      "SVM                  0.76156          0.23844\n",
      "CART                 0.44376          0.55624\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         Class 3         \n",
      "--------------------------------------------------------------------\n",
      "DLGN                0.91562    0.92763    0.93990    0.94096    \n",
      "Random Forest       0.44407    0.59079    0.63494    0.59784    \n",
      "SVM                 0.69867    0.74191    0.80064    0.80416    \n",
      "CART                0.36340    0.46118    0.48494    0.46453    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 40\n",
      "  Total Samples: 100000\n",
      "  Number of Classes: 4\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 25000\n",
      "  Class 1: 25000\n",
      "  Class 2: 25000\n",
      "  Class 3: 25000\n",
      "\n",
      "Data split:\n",
      "  Training: 50000\n",
      "  Validation: 25000\n",
      "  Test: 25000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [03:14<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.110852\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.50300\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.69116\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.38880\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.93836          0.06164\n",
      "Random Forest        0.50300          0.49700\n",
      "SVM                  0.69116          0.30884\n",
      "CART                 0.38880          0.61120\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         Class 3         \n",
      "--------------------------------------------------------------------\n",
      "DLGN                0.90940    0.94603    0.94218    0.95590    \n",
      "Random Forest       0.29025    0.59006    0.56770    0.56307    \n",
      "SVM                 0.57842    0.74454    0.68780    0.75389    \n",
      "CART                0.31366    0.39332    0.43485    0.41326    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 50\n",
      "  Total Samples: 100000\n",
      "  Number of Classes: 4\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 25000\n",
      "  Class 1: 25000\n",
      "  Class 2: 25000\n",
      "  Class 3: 25000\n",
      "\n",
      "Data split:\n",
      "  Training: 50000\n",
      "  Validation: 25000\n",
      "  Test: 25000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [03:51<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.079362\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.55016\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.71664\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.40940\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.94072          0.05928\n",
      "Random Forest        0.55016          0.44984\n",
      "SVM                  0.71664          0.28336\n",
      "CART                 0.40940          0.59060\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         Class 3         \n",
      "--------------------------------------------------------------------\n",
      "DLGN                0.91994    0.94255    0.93053    0.96938    \n",
      "Random Forest       0.42426    0.50465    0.48648    0.78137    \n",
      "SVM                 0.63359    0.70411    0.66316    0.86314    \n",
      "CART                0.35299    0.36280    0.35676    0.56227    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 30\n",
      "  Total Samples: 100000\n",
      "  Number of Classes: 5\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 20000\n",
      "  Class 1: 20000\n",
      "  Class 2: 20000\n",
      "  Class 3: 20000\n",
      "  Class 4: 20000\n",
      "\n",
      "Data split:\n",
      "  Training: 50000\n",
      "  Validation: 25000\n",
      "  Test: 25000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [04:12<00:00,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.077875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.60756\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.80772\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.43884\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.95112          0.04888\n",
      "Random Forest        0.60756          0.39244\n",
      "SVM                  0.80772          0.19228\n",
      "CART                 0.43884          0.56116\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         Class 3         Class 4         \n",
      "--------------------------------------------------------------------------------\n",
      "DLGN                0.95696    0.94759    0.95576    0.94384    0.95157    \n",
      "Random Forest       0.62160    0.61912    0.69249    0.47481    0.63036    \n",
      "SVM                 0.82460    0.80516    0.86607    0.72655    0.81676    \n",
      "CART                0.42550    0.43469    0.49069    0.37602    0.46709    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 40\n",
      "  Total Samples: 100000\n",
      "  Number of Classes: 5\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 20000\n",
      "  Class 1: 20000\n",
      "  Class 2: 20000\n",
      "  Class 3: 20000\n",
      "  Class 4: 20000\n",
      "\n",
      "Data split:\n",
      "  Training: 50000\n",
      "  Validation: 25000\n",
      "  Test: 25000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [04:16<00:00,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.080675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.52392\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.74236\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.36644\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.94696          0.05304\n",
      "Random Forest        0.52392          0.47608\n",
      "SVM                  0.74236          0.25764\n",
      "CART                 0.36644          0.63356\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         Class 3         Class 4         \n",
      "--------------------------------------------------------------------------------\n",
      "DLGN                0.95787    0.95311    0.93456    0.94144    0.94780    \n",
      "Random Forest       0.43539    0.70725    0.53242    0.58355    0.35836    \n",
      "SVM                 0.70907    0.83885    0.75761    0.76025    0.64425    \n",
      "CART                0.33748    0.44858    0.37940    0.37686    0.28830    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DLGN Multiclass Classification with Baseline Comparison\n",
      "============================================================\n",
      "\n",
      "Dataset Configuration:\n",
      "  Input Dimension: 50\n",
      "  Total Samples: 100000\n",
      "  Number of Classes: 5\n",
      "  Tree Levels: 4\n",
      "\n",
      "Generating data...\n",
      "\n",
      "Label distribution:\n",
      "  Class 0: 20000\n",
      "  Class 1: 20000\n",
      "  Class 2: 20000\n",
      "  Class 3: 20000\n",
      "  Class 4: 20000\n",
      "\n",
      "Data split:\n",
      "  Training: 50000\n",
      "  Validation: 25000\n",
      "  Test: 25000\n",
      "\n",
      "DLGN Configuration:\n",
      "  Mode: dlgn\n",
      "  Beta: 4\n",
      "  Learning Rate: 0.002\n",
      "  Hidden Layers: 4\n",
      "  Hidden Nodes: [20, 20, 20, 20]\n",
      "\n",
      "============================================================\n",
      "Training DLGN...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [03:21<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Train Loss: 0.091058\n",
      "\n",
      "============================================================\n",
      "Training Baseline Models\n",
      "============================================================\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test Accuracy: 0.50256\n",
      "\n",
      "Training SVM...\n",
      "SVM Test Accuracy: 0.70312\n",
      "\n",
      "Training CART...\n",
      "CART Test Accuracy: 0.34144\n",
      "\n",
      "============================================================\n",
      "Comprehensive Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model                Test Accuracy   Error Rate     \n",
      "--------------------------------------------------\n",
      "DLGN                 0.93900          0.06100\n",
      "Random Forest        0.50256          0.49744\n",
      "SVM                  0.70312          0.29688\n",
      "CART                 0.34144          0.65856\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Model               Class 0         Class 1         Class 2         Class 3         Class 4         \n",
      "--------------------------------------------------------------------------------\n",
      "DLGN                0.91987    0.95611    0.93554    0.95121    0.93241    \n",
      "Random Forest       0.45702    0.51583    0.41459    0.72621    0.40242    \n",
      "SVM                 0.69458    0.72285    0.64001    0.81996    0.64016    \n",
      "CART                0.28569    0.36774    0.27981    0.46210    0.31276    \n",
      "\n",
      "============================================================\n",
      "Experiment Complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Utility functions\n",
    "def set_npseed(seed):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def set_torchseed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Data generation function\n",
    "def data_gen_decision_tree(num_data=1000, dim=2, seed=0, w_list=None, b_list=None, \n",
    "                           vals=None, num_levels=3, threshold=1e-6, num_classes=4):        \n",
    "    set_npseed(seed=seed)\n",
    "    num_internal_nodes = 2**num_levels - 1\n",
    "    num_leaf_nodes = 2**num_levels\n",
    "    stats = np.zeros(num_internal_nodes+num_leaf_nodes)\n",
    "\n",
    "    if vals is None:\n",
    "        vals = np.arange(0, num_internal_nodes+num_leaf_nodes, 1, dtype=np.int32)\n",
    "        vals[:num_internal_nodes] = -99\n",
    "        \n",
    "        # Assign classes to leaf nodes\n",
    "        leaf_indices = np.arange(num_internal_nodes, num_internal_nodes+num_leaf_nodes)\n",
    "        class_assignments = np.tile(np.arange(num_classes), (num_leaf_nodes // num_classes) + 1)[:num_leaf_nodes]\n",
    "        np.random.shuffle(class_assignments)\n",
    "        vals[leaf_indices] = class_assignments\n",
    "\n",
    "    if w_list is None:\n",
    "        w_list = np.random.randn(num_internal_nodes, dim)\n",
    "        w_list /= np.linalg.norm(w_list, axis=1)[:, None]\n",
    "        b_list = np.random.uniform(-0.5, 0.5, size=(num_internal_nodes,))\n",
    "\n",
    "    oversample_factor = 2.0\n",
    "    num_data_initial = int(num_data * oversample_factor)\n",
    "    \n",
    "    data_x = np.random.uniform(-1, 1, size=(num_data_initial, dim))\n",
    "    relevant_stats = data_x @ w_list.T + b_list\n",
    "    curr_index = np.zeros(shape=(num_data_initial), dtype=int)\n",
    "    \n",
    "    for level in range(num_levels):\n",
    "        decision_variable = np.choose(curr_index, relevant_stats.T)\n",
    "        curr_index = (curr_index+1)*2 - (1-(decision_variable > 0))\n",
    "        \n",
    "    bound_dist = np.min(np.abs(relevant_stats), axis=1)\n",
    "    labels = vals[curr_index]\n",
    "    \n",
    "    data_x_pruned = data_x[bound_dist>threshold]\n",
    "    labels_pruned = labels[bound_dist>threshold]\n",
    "    \n",
    "    samples_per_class = num_data // num_classes\n",
    "    \n",
    "    balanced_data = []\n",
    "    balanced_labels = []\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        cls_mask = labels_pruned == cls\n",
    "        cls_data = data_x_pruned[cls_mask]\n",
    "        \n",
    "        if len(cls_data) >= samples_per_class:\n",
    "            indices = np.random.choice(len(cls_data), samples_per_class, replace=False)\n",
    "            balanced_data.append(cls_data[indices])\n",
    "            balanced_labels.append(np.full(samples_per_class, cls))\n",
    "        else:\n",
    "            indices = np.random.choice(len(cls_data), samples_per_class, replace=True)\n",
    "            balanced_data.append(cls_data[indices])\n",
    "            balanced_labels.append(np.full(samples_per_class, cls))\n",
    "    \n",
    "    data_x_balanced = np.vstack(balanced_data)\n",
    "    labels_balanced = np.concatenate(balanced_labels)\n",
    "    \n",
    "    shuffle_idx = np.random.permutation(len(data_x_balanced))\n",
    "    data_x_balanced = data_x_balanced[shuffle_idx]\n",
    "    labels_balanced = labels_balanced[shuffle_idx]\n",
    "    \n",
    "    relevant_stats = np.sign(data_x_balanced @ w_list.T + b_list)\n",
    "    nodes_active = np.zeros((len(data_x_balanced), num_internal_nodes+num_leaf_nodes), dtype=np.int32)\n",
    "    for node in range(num_internal_nodes+num_leaf_nodes):\n",
    "        if node==0:\n",
    "            stats[node]=len(relevant_stats)\n",
    "            nodes_active[:,0]=1\n",
    "            continue\n",
    "        parent = (node-1)//2\n",
    "        nodes_active[:,node]=nodes_active[:,parent]\n",
    "        right_child = node-(parent*2)-1\n",
    "        if right_child==1:\n",
    "            nodes_active[:,node] *= relevant_stats[:,parent]>0\n",
    "        if right_child==0:\n",
    "            nodes_active[:,node] *= relevant_stats[:,parent]<0\n",
    "        stats = nodes_active.sum(axis=0)\n",
    "    \n",
    "    return ((data_x_balanced, labels_balanced), (w_list, b_list, vals), stats)\n",
    "\n",
    "# DLGN Model (Multiclass)\n",
    "class DLGN_FC(nn.Module):\n",
    "    def __init__(self, input_dim=None, output_dim=None, num_hidden_nodes=[], \n",
    "                 beta=30, dlgn_mode='dlgn_sf', mode='pwc', num_classes=4):\t\t\n",
    "        super(DLGN_FC, self).__init__()\n",
    "        self.num_hidden_layers = len(num_hidden_nodes)\n",
    "        self.beta = beta\n",
    "        self.dlgn_mode = dlgn_mode\n",
    "        self.mode = mode\n",
    "        self.num_classes = num_classes\n",
    "        self.num_nodes = [input_dim] + num_hidden_nodes + [num_classes]\n",
    "        self.gating_layers = nn.ModuleList()\n",
    "        self.value_layers = nn.ModuleList()\n",
    "\n",
    "        for i in range(self.num_hidden_layers+1):\n",
    "            if i != self.num_hidden_layers:\n",
    "                if self.dlgn_mode == 'dlgn_sf':\n",
    "                    temp = nn.Linear(self.num_nodes[0], self.num_nodes[i+1], bias=False)\n",
    "                else:\n",
    "                    temp = nn.Linear(self.num_nodes[i], self.num_nodes[i+1], bias=False)\n",
    "                self.gating_layers.append(temp)\n",
    "            temp = nn.Linear(self.num_nodes[i], self.num_nodes[i+1], bias=False)\n",
    "            self.value_layers.append(temp)\n",
    "    \n",
    "    def set_parameters_with_mask(self, to_copy, parameter_masks):\n",
    "        for (name, copy_param) in to_copy.named_parameters():\n",
    "            copy_param = copy_param.clone().detach()\n",
    "            orig_param = self.state_dict()[name]\n",
    "            if name in parameter_masks:\n",
    "                param_mask = parameter_masks[name] > 0\n",
    "                orig_param[param_mask] = copy_param[param_mask]\n",
    "            else:\n",
    "                orig_param = copy_param.data.detach()\n",
    "\n",
    "    def return_gating_functions(self):\n",
    "        effective_weights = []\n",
    "        for i in range(self.num_hidden_layers):\n",
    "            curr_weight = self.gating_layers[i].weight.detach().clone()\n",
    "            if self.dlgn_mode == 'dlgn_sf':\n",
    "                effective_weights.append(curr_weight)\n",
    "            else:\n",
    "                if i == 0:\n",
    "                    effective_weights.append(curr_weight)\n",
    "                else:\n",
    "                    effective_weights.append(torch.matmul(curr_weight, effective_weights[-1]))\n",
    "        return effective_weights\n",
    "\n",
    "    def forward(self, x):\n",
    "        gate_scores = [x]\n",
    "\n",
    "        for el in self.parameters():\n",
    "            if el.is_cuda:\n",
    "                device = torch.device('cuda:0')\n",
    "            else:\n",
    "                device = torch.device('cpu')\n",
    "        \n",
    "        if self.mode == 'pwc':\n",
    "            values = [torch.ones(x.shape).to(device)]\n",
    "        else:\n",
    "            values = [x.to(device)]\n",
    "\n",
    "        for i in range(self.num_hidden_layers):\n",
    "            if self.dlgn_mode == 'dlgn_sf':\n",
    "                gate_scores.append((x @ self.gating_layers[i].weight.T))\n",
    "            else:\n",
    "                gate_scores.append(self.gating_layers[i].to(device)(gate_scores[-1].to(device)))\n",
    "            curr_gate_on_off = torch.sigmoid(self.beta * gate_scores[-1])\n",
    "            values.append(self.value_layers[i](values[-1]) * curr_gate_on_off)\n",
    "        \n",
    "        values.append(self.value_layers[self.num_hidden_layers](values[-1]))\n",
    "        return values, gate_scores\n",
    "\n",
    "# Training function (Multiclass)\n",
    "def train_dlgn(DLGN_obj, train_data_curr, vali_data_curr, test_data_curr,\n",
    "               train_labels_curr, test_labels_curr, vali_labels_curr, \n",
    "               num_epoch=1, parameter_mask=None, seed=42, lr=0.001, \n",
    "               no_of_batches=10, saved_epochs=None, x_epoch=1000):\n",
    "    \n",
    "    if parameter_mask is None:\n",
    "        parameter_mask = {name: torch.ones_like(param) \n",
    "                         for name, param in DLGN_obj.named_parameters()}\n",
    "    \n",
    "    if saved_epochs is None:\n",
    "        saved_epochs = list(range(0, num_epoch, 100)) + [num_epoch-1]\n",
    "    \n",
    "    set_torchseed(seed)\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    DLGN_obj.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(DLGN_obj.parameters(), lr=lr)\n",
    "\n",
    "    train_data_torch = torch.Tensor(train_data_curr)\n",
    "    vali_data_torch = torch.Tensor(vali_data_curr)\n",
    "    test_data_torch = torch.Tensor(test_data_curr)\n",
    "\n",
    "    train_labels_torch = torch.tensor(train_labels_curr, dtype=torch.int64)\n",
    "    test_labels_torch = torch.tensor(test_labels_curr, dtype=torch.int64)\n",
    "    vali_labels_torch = torch.tensor(vali_labels_curr, dtype=torch.int64)\n",
    "\n",
    "    num_batches = no_of_batches\n",
    "    batch_size = len(train_data_curr) // num_batches\n",
    "    losses = []\n",
    "    DLGN_obj_store = []\n",
    "    best_vali_error = len(vali_labels_curr)\n",
    "    debug_models = []\n",
    "    train_losses = []\n",
    "\n",
    "    for epoch in tqdm(range(saved_epochs[-1]+1)):\n",
    "        if epoch in saved_epochs:\n",
    "            DLGN_obj_copy = deepcopy(DLGN_obj)\n",
    "            DLGN_obj_copy.to(torch.device('cpu'))\n",
    "            DLGN_obj_store.append(DLGN_obj_copy)\n",
    "            \n",
    "            train_outputs_values, train_outputs_gate_scores = DLGN_obj(\n",
    "                torch.Tensor(train_data_curr).to(device))\n",
    "            train_preds = train_outputs_values[-1]\n",
    "            \n",
    "            targets = torch.tensor(train_labels_curr, dtype=torch.int64).to(device)\n",
    "            train_loss = criterion(train_preds, targets)\n",
    "\n",
    "            train_losses.append(train_loss)\n",
    "            if epoch % 1500 == 0 and epoch!=0:\n",
    "                print(f\"Epoch {epoch}, Train Loss: {train_loss.item():.6f}\")\n",
    "            if train_loss < 5e-6:\n",
    "                break\n",
    "            if np.isnan(train_loss.detach().cpu().numpy()):\n",
    "                break\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        for batch_start in range(0, len(train_data_curr), batch_size):\n",
    "            if (batch_start + batch_size) > len(train_data_curr):\n",
    "                break\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            inputs = train_data_torch[batch_start:batch_start+batch_size]\n",
    "            targets = train_labels_torch[batch_start:batch_start+batch_size].reshape(batch_size)\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            values, gate_scores = DLGN_obj(inputs)\n",
    "            outputs = values[-1]\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            \n",
    "            for name, param in DLGN_obj.named_parameters():\n",
    "                parameter_mask[name] = parameter_mask[name].to(device)\n",
    "                param.grad *= parameter_mask[name]   \n",
    "                if \"gat\" in name and epoch > x_epoch:\n",
    "                    param.grad *= 0.\n",
    "            \n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        train_outputs_values, train_outputs_gate_scores = DLGN_obj(\n",
    "            torch.Tensor(train_data_curr).to(device))\n",
    "        train_preds = train_outputs_values[-1]\n",
    "        targets = torch.tensor(train_labels_curr, dtype=torch.int64).to(device)\n",
    "        train_loss = criterion(train_preds, targets)\n",
    "\n",
    "        losses.append(train_loss.cpu().detach().clone().numpy())\n",
    "        \n",
    "        inputs = vali_data_torch.to(device)\n",
    "        targets = vali_labels_torch.to(device)\n",
    "        values, gate_scores = DLGN_obj(inputs)\n",
    "        \n",
    "        vali_preds = torch.argmax(values[-1], dim=1)\n",
    "        vali_error = torch.sum(targets != vali_preds)\n",
    "        \n",
    "        if vali_error < best_vali_error:\n",
    "            DLGN_obj_return = deepcopy(DLGN_obj)\n",
    "            best_vali_error = vali_error\n",
    "            \n",
    "    DLGN_obj_return.to(torch.device('cpu'))\n",
    "    return train_losses, DLGN_obj_return, DLGN_obj_store, losses, debug_models\n",
    "\n",
    "# Baseline comparison functions\n",
    "def train_baseline_models(train_data, train_labels, test_data, test_labels, num_classes):\n",
    "    \"\"\"Train and evaluate baseline ML models\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Training Baseline Models\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Random Forest\n",
    "    print(\"\\nTraining Random Forest...\")\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "    rf.fit(train_data, train_labels)\n",
    "    rf_preds = rf.predict(test_data)\n",
    "    rf_acc = accuracy_score(test_labels, rf_preds)\n",
    "    results['Random Forest'] = {\n",
    "        'accuracy': rf_acc,\n",
    "        'predictions': rf_preds,\n",
    "        'model': rf\n",
    "    }\n",
    "    print(f\"Random Forest Test Accuracy: {rf_acc:.5f}\")\n",
    "    \n",
    "    # SVM\n",
    "    print(\"\\nTraining SVM...\")\n",
    "    svm = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "    svm.fit(train_data, train_labels)\n",
    "    svm_preds = svm.predict(test_data)\n",
    "    svm_acc = accuracy_score(test_labels, svm_preds)\n",
    "    results['SVM'] = {\n",
    "        'accuracy': svm_acc,\n",
    "        'predictions': svm_preds,\n",
    "        'model': svm\n",
    "    }\n",
    "    print(f\"SVM Test Accuracy: {svm_acc:.5f}\")\n",
    "    \n",
    "    # CART (Decision Tree)\n",
    "    print(\"\\nTraining CART...\")\n",
    "    cart = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "    cart.fit(train_data, train_labels)\n",
    "    cart_preds = cart.predict(test_data)\n",
    "    cart_acc = accuracy_score(test_labels, cart_preds)\n",
    "    results['CART'] = {\n",
    "        'accuracy': cart_acc,\n",
    "        'predictions': cart_preds,\n",
    "        'model': cart\n",
    "    }\n",
    "    print(f\"CART Test Accuracy: {cart_acc:.5f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_comparison_table(dlgn_acc, baseline_results, num_classes, test_labels):\n",
    "    \"\"\"Print comparison table of all models\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Model Comparison\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\n{'Model':<20} {'Test Accuracy':<15} {'Error Rate':<15}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'DLGN':<20} {dlgn_acc:.5f} {' '*8} {1-dlgn_acc:.5f}\")\n",
    "    \n",
    "    for model_name, results in baseline_results.items():\n",
    "        acc = results['accuracy']\n",
    "        print(f\"{model_name:<20} {acc:.5f} {' '*8} {1-acc:.5f}\")\n",
    "    \n",
    "    # Per-class accuracy comparison\n",
    "    print(f\"\\n{'Model':<20}\", end=\"\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"Class {i:<8}\", end=\"\")\n",
    "    print()\n",
    "    print(\"-\" * (20 + num_classes * 15))\n",
    "    \n",
    "    # DLGN per-class\n",
    "    print(f\"{'DLGN':<20}\", end=\"\")\n",
    "    for i in range(num_classes):\n",
    "        class_mask = test_labels == i\n",
    "        class_total = np.sum(class_mask)\n",
    "        if class_total > 0:\n",
    "            # This will be calculated outside and passed\n",
    "            print(f\"{0:.5f}{' '*3}\", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    # Baseline per-class\n",
    "    for model_name, results in baseline_results.items():\n",
    "        print(f\"{model_name:<20}\", end=\"\")\n",
    "        preds = results['predictions']\n",
    "        for i in range(num_classes):\n",
    "            class_mask = test_labels == i\n",
    "            class_correct = np.sum((test_labels[class_mask] == preds[class_mask]))\n",
    "            class_total = np.sum(class_mask)\n",
    "            if class_total > 0:\n",
    "                print(f\"{class_correct/class_total:.5f}{' '*3}\", end=\"\")\n",
    "        print()\n",
    "\n",
    "# Main training loop\n",
    "for num_data1 in [40000, 60000, 100000]:\n",
    "    for num_classes1 in [3, 4, 5]:\n",
    "        for input_dim1 in [30, 40, 50]:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"DLGN Multiclass Classification with Baseline Comparison\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            # Configuration\n",
    "            seed = 365\n",
    "            num_levels = 4\n",
    "            threshold = 0\n",
    "            num_classes = num_classes1\n",
    "            input_dim = input_dim1\n",
    "            num_data = num_data1\n",
    "            \n",
    "            print(f\"\\nDataset Configuration:\")\n",
    "            print(f\"  Input Dimension: {input_dim}\")\n",
    "            print(f\"  Total Samples: {num_data}\")\n",
    "            print(f\"  Number of Classes: {num_classes}\")\n",
    "            print(f\"  Tree Levels: {num_levels}\")\n",
    "            \n",
    "            # Generate data\n",
    "            print(\"\\nGenerating data...\")\n",
    "            ((data_x, labels), (w_list, b_list, vals), stats) = data_gen_decision_tree(\n",
    "                dim=input_dim, \n",
    "                seed=seed, \n",
    "                num_levels=num_levels,\n",
    "                num_data=num_data,\n",
    "                num_classes=num_classes\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nLabel distribution:\")\n",
    "            for i in range(num_classes):\n",
    "                print(f\"  Class {i}: {sum(labels == i)}\")\n",
    "            \n",
    "            # Split data\n",
    "            num_train = num_data // 2\n",
    "            num_vali = num_data // 4\n",
    "            num_test = num_data // 4\n",
    "            \n",
    "            train_data = data_x[:num_train, :]\n",
    "            train_data_labels = labels[:num_train]\n",
    "            \n",
    "            vali_data = data_x[num_train:num_train + num_vali, :]\n",
    "            vali_data_labels = labels[num_train:num_train + num_vali]\n",
    "            \n",
    "            test_data = data_x[num_train + num_vali:, :]\n",
    "            test_data_labels = labels[num_train + num_vali:]\n",
    "            \n",
    "            print(f\"\\nData split:\")\n",
    "            print(f\"  Training: {len(train_data)}\")\n",
    "            print(f\"  Validation: {len(vali_data)}\")\n",
    "            print(f\"  Test: {len(test_data)}\")\n",
    "            \n",
    "            # Model configuration\n",
    "            dlgn_mode = 'dlgn'\n",
    "            beta = 4\n",
    "            lr = 0.002\n",
    "            num_hidden_layers = 4\n",
    "            num_hidden_nodes = [20, 20, 20, 20]\n",
    "            no_of_batches = 10\n",
    "            x_epoch = 1500\n",
    "            saved_epochs = list(range(0, 1501, 100))\n",
    "            \n",
    "            print(f\"\\nDLGN Configuration:\")\n",
    "            print(f\"  Mode: {dlgn_mode}\")\n",
    "            print(f\"  Beta: {beta}\")\n",
    "            print(f\"  Learning Rate: {lr}\")\n",
    "            print(f\"  Hidden Layers: {num_hidden_layers}\")\n",
    "            print(f\"  Hidden Nodes: {num_hidden_nodes}\")\n",
    "            \n",
    "            # Initialize DLGN model\n",
    "            set_torchseed(6675)\n",
    "            DLGN_init = DLGN_FC(\n",
    "                input_dim=input_dim, \n",
    "                output_dim=1,\n",
    "                num_hidden_nodes=num_hidden_nodes, \n",
    "                beta=beta, \n",
    "                dlgn_mode=dlgn_mode,\n",
    "                mode='pwc',\n",
    "                num_classes=num_classes\n",
    "            )\n",
    "            \n",
    "            # Setup parameter masks\n",
    "            device = 'cpu'\n",
    "            train_parameter_masks = dict()\n",
    "            for name, parameter in DLGN_init.named_parameters():\n",
    "                train_parameter_masks[name] = torch.ones_like(parameter).to(device)\n",
    "            \n",
    "            # Train DLGN model\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"Training DLGN...\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            set_torchseed(5000)\n",
    "            train_losses, DLGN_obj_final, DLGN_obj_store, losses, debug_models = train_dlgn(\n",
    "                train_data_curr=train_data,\n",
    "                vali_data_curr=vali_data,\n",
    "                test_data_curr=test_data,\n",
    "                train_labels_curr=train_data_labels,\n",
    "                vali_labels_curr=vali_data_labels,\n",
    "                test_labels_curr=test_data_labels,\n",
    "                DLGN_obj=deepcopy(DLGN_init),\n",
    "                parameter_mask=train_parameter_masks,\n",
    "                lr=lr,\n",
    "                no_of_batches=no_of_batches,\n",
    "                saved_epochs=saved_epochs,\n",
    "                x_epoch=x_epoch\n",
    "            )\n",
    "            \n",
    "            # Evaluate DLGN on test set\n",
    "            test_outputs_values, test_outputs_gate_scores = DLGN_obj_final(torch.Tensor(test_data))\n",
    "            test_logits = test_outputs_values[-1].detach().numpy()\n",
    "            dlgn_preds = np.argmax(test_logits, axis=1)\n",
    "            \n",
    "            dlgn_acc = accuracy_score(test_data_labels, dlgn_preds)\n",
    "            \n",
    "            # Train baseline models\n",
    "            baseline_results = train_baseline_models(\n",
    "                train_data, train_data_labels, \n",
    "                test_data, test_data_labels, \n",
    "                num_classes\n",
    "            )\n",
    "            \n",
    "            # Print comprehensive comparison\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"Comprehensive Model Comparison\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            print(f\"\\n{'Model':<20} {'Test Accuracy':<15} {'Error Rate':<15}\")\n",
    "            print(\"-\" * 50)\n",
    "            print(f\"{'DLGN':<20} {dlgn_acc:.5f} {' '*8} {1-dlgn_acc:.5f}\")\n",
    "            \n",
    "            for model_name, results in baseline_results.items():\n",
    "                acc = results['accuracy']\n",
    "                print(f\"{model_name:<20} {acc:.5f} {' '*8} {1-acc:.5f}\")\n",
    "            \n",
    "            # Per-class accuracy comparison\n",
    "            print(f\"\\nPer-Class Accuracy:\")\n",
    "            print(f\"{'Model':<20}\", end=\"\")\n",
    "            for i in range(num_classes):\n",
    "                print(f\"Class {i:<10}\", end=\"\")\n",
    "            print()\n",
    "            print(\"-\" * (20 + num_classes * 12))\n",
    "            \n",
    "            # DLGN per-class\n",
    "            print(f\"{'DLGN':<20}\", end=\"\")\n",
    "            for i in range(num_classes):\n",
    "                class_mask = test_data_labels == i\n",
    "                class_correct = np.sum((test_data_labels[class_mask] == dlgn_preds[class_mask]))\n",
    "                class_total = np.sum(class_mask)\n",
    "                if class_total > 0:\n",
    "                    print(f\"{class_correct/class_total:.5f} {' '*3}\", end=\"\")\n",
    "            print()\n",
    "            \n",
    "            # Baseline per-class\n",
    "            for model_name, results in baseline_results.items():\n",
    "                print(f\"{model_name:<20}\", end=\"\")\n",
    "                preds = results['predictions']\n",
    "                for i in range(num_classes):\n",
    "                    class_mask = test_data_labels == i\n",
    "                    class_correct = np.sum((test_data_labels[class_mask] == preds[class_mask]))\n",
    "                    class_total = np.sum(class_mask)\n",
    "                    if class_total > 0:\n",
    "                        print(f\"{class_correct/class_total:.5f} {' '*3}\", end=\"\")\n",
    "                print()\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"Experiment Complete!\")\n",
    "            print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dffbc2",
   "metadata": {
    "papermill": {
     "duration": 1.747085,
     "end_time": "2025-11-19T13:56:52.346185",
     "exception": false,
     "start_time": "2025-11-19T13:56:50.599100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8874.720928,
   "end_time": "2025-11-19T13:56:57.192695",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-19T11:29:02.471767",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
